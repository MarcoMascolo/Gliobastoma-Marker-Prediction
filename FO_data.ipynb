{
 "cells": [
  {
   "cell_type": "raw",
   "id": "a7ef3a52",
   "metadata": {},
   "source": [
    "how can i creae a script on jupyter notebook that opens files for docmi the doctor type file for brain mri from the following folder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adde81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import pydicom\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create a single figure and image object at the start\n",
    "plt.figure(figsize=(7,7))\n",
    "img = plt.imshow(np.zeros((512, 512)), cmap=plt.cm.bone)\n",
    "\n",
    "def load_and_display_image(file_path):\n",
    "    ds = pydicom.dcmread(file_path)\n",
    "    window_center = ds.WindowCenter if 'WindowCenter' in ds else np.mean(ds.pixel_array)\n",
    "    window_width = ds.WindowWidth if 'WindowWidth' in ds else np.max(ds.pixel_array) - np.min(ds.pixel_array)\n",
    "    \n",
    "    img_min = window_center - window_width // 2\n",
    "    img_max = window_center + window_width // 2\n",
    "    img_data = ds.pixel_array.copy()\n",
    "    img_data[img_data < img_min] = img_min\n",
    "    img_data[img_data > img_max] = img_max\n",
    "    img_data = (img_data - np.min(img_data)) / (np.max(img_data) - np.min(img_data)) * 255  # Normalize to 0-255\n",
    "\n",
    "    img.set_data(img_data)\n",
    "    plt.draw()\n",
    "\n",
    "    \n",
    "dicom_dir = r\"C:\\Users\\MarcoMascolo\\Downloads\\MRI\\TO_organized\"\n",
    "patient_folders = [os.path.join(dicom_dir, patient_folder) for patient_folder in os.listdir(dicom_dir) if os.path.isdir(os.path.join(dicom_dir, patient_folder))]\n",
    "\n",
    "sequence_folders = []\n",
    "for patient_folder in patient_folders:\n",
    "    for sequence_folder in os.listdir(patient_folder):\n",
    "        if any(seq in sequence_folder for seq in ['T1', 'T2', 'T2_FLAIR']):\n",
    "            sequence_folders.append(os.path.join(patient_folder, sequence_folder))\n",
    "\n",
    "current_folder = sequence_folders[0]  # Start with the first patient and sequence\n",
    "dicom_files = [os.path.join(current_folder, f) for f in os.listdir(current_folder) if True]  # Change made here\n",
    "\n",
    "def update_slider(change):\n",
    "    current_file = dicom_files[change.new]\n",
    "    load_and_display_image(current_file)\n",
    "\n",
    "def update_folder(change):\n",
    "    global dicom_files\n",
    "    current_folder = sequence_folders[change.new]\n",
    "    dicom_files = [os.path.join(current_folder, f) for f in os.listdir(current_folder) if True]  # And here\n",
    "    if dicom_files:  # Add this condition\n",
    "        slider.max = len(dicom_files) - 1\n",
    "        slider.value = 0\n",
    "\n",
    "folder_dropdown = widgets.Dropdown(options=[(f.split(os.sep)[-2:], i) for i, f in enumerate(sequence_folders)], description='Patient & Sequence:')\n",
    "if dicom_files:  # And this one\n",
    "    slider = widgets.IntSlider(min=0, max=len(dicom_files)-1, step=1, description='Image Index:')\n",
    "    folder_dropdown.observe(update_folder, names='value')\n",
    "    slider.observe(update_slider, names='value')\n",
    "\n",
    "display(folder_dropdown)\n",
    "if dicom_files:  # And this one\n",
    "    display(slider)\n",
    "    load_and_display_image(dicom_files[0])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c141232",
   "metadata": {},
   "source": [
    "import os\n",
    "import pydicom\n",
    "\n",
    "folder_path = r\"C:\\Users\\MarcoMascolo\\Downloads\\ML Glioma\\FO\\FO01\\exam\\QOHZNKWU\\3FZJKP01\"\n",
    "folder_path = r\"C:\\Users\\MarcoMascolo\\Downloads\\ML Glioma\\FO\\FO04 -\\DICOM\"\n",
    "# List all files in the directory\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Filter list for DICOM files\n",
    "dicom_files = [f for f in files if f.endswith(\".dcm\")]\n",
    "\n",
    "# Create an empty list to store the DICOM objects\n",
    "dicom_objects = []\n",
    "\n",
    "for file in dicom_files:\n",
    "    # Create full file path\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    \n",
    "    # Read the DICOM object\n",
    "    dicom_object = pydicom.dcmread(file_path)\n",
    "    \n",
    "    # Append the DICOM object to the list\n",
    "    dicom_objects.append(dicom_object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f0b313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "folder_path = r\"C:\\Users\\MarcoMascolo\\Downloads\\MRI\\FO\"\n",
    "\n",
    "# Iterate through all files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "    # Check if the file is a zip file\n",
    "    if file_name.endswith('.zip'):\n",
    "        # Extract the zip file to the same folder\n",
    "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(folder_path)\n",
    "\n",
    "        # Optionally, you can delete the zip file after extraction\n",
    "        os.remove(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae88577",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Folder path\n",
    "# folder_path = r\"C:\\Users\\MarcoMascolo\\Downloads\\ML Glioma\\FO\\FO01\\exam\\QOHZNKWU\\3FZJKP01\"\n",
    "# folder_path = r\"C:\\Users\\MarcoMascolo\\Downloads\\MRI\\FO\\FO04\\DICOM\"\n",
    "folder_path = r\"C:\\Users\\MarcoMascolo\\Downloads\\MRI\\FO\\FO05\\DICOM\"\n",
    "folder_path = r\"C:\\Users\\MarcoMascolo\\Downloads\\MRI\\FO\\FO07\\DICOM\"\n",
    "# folder_path = r\"C:\\Users\\MarcoMascolo\\Downloads\\ML Glioma\\FO\\FO07 -\\DICOM\"\n",
    "\n",
    "# List all files in the directory\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Filter list for DICOM files\n",
    "dicom_files = [f for f in files if f.endswith(\".dcm\")]\n",
    "\n",
    "# Sort dicom_files in case the file names correspond to the scan order\n",
    "dicom_files.sort()\n",
    "\n",
    "# Create an empty list to store the DICOM objects\n",
    "dicom_images = []\n",
    "\n",
    "for file in dicom_files:\n",
    "    # Create full file path\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    \n",
    "    # Try reading the DICOM object and append the pixel data to the list\n",
    "    try:\n",
    "        dicom_object = pydicom.dcmread(file_path)\n",
    "        dicom_images.append(dicom_object.pixel_array)\n",
    "    except AttributeError:\n",
    "        print(f\"File {file} does not contain pixel data in a convertible format.\")\n",
    "        \n",
    "def update_image(index):\n",
    "    plt.figure(figsize=(10, 10))  # Increase the size as needed\n",
    "    plt.imshow(dicom_images[index], cmap=plt.cm.bone)\n",
    "    plt.show()\n",
    "    \n",
    "# Make sure dicom_images is not empty\n",
    "\n",
    "if dicom_images:\n",
    "    plt.figure(figsize=(10, 10))  # Increase the size as needed\n",
    "\n",
    "    # Create a slider for image selection\n",
    "    slider = widgets.IntSlider(min=0, max=len(dicom_images) - 1, step=1, value=0)\n",
    "\n",
    "    # Update the image when the slider changes\n",
    "    widgets.interact(update_image, index=slider)\n",
    "\n",
    "    # Display the first image\n",
    "    plt.imshow(dicom_images[0], cmap=plt.cm.bone)\n",
    "else:\n",
    "    print(\"No convertible pixel data found in the files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767de3fa",
   "metadata": {},
   "source": [
    "///////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f77447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5d8eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.countplot(data=train_df, x=\"MGMT_value\");\n",
    "\n",
    "def load_dicom(path):\n",
    "    dicom = pydicom.read_file(path)\n",
    "    data = dicom.pixel_array\n",
    "    data = data - np.min(data)\n",
    "    if np.max(data) != 0:\n",
    "        data = data / np.max(data)\n",
    "    data = (data * 255).astype(np.uint8)\n",
    "    return data\n",
    "\n",
    "\n",
    "def visualize_sample(\n",
    "    brats21id, \n",
    "    slice_i,\n",
    "    mgmt_value,\n",
    "    types=(\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\")\n",
    "):\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    patient_path = os.path.join(\n",
    "        \"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/\", \n",
    "        str(brats21id).zfill(5),\n",
    "    )\n",
    "    for i, t in enumerate(types, 1):\n",
    "        t_paths = sorted(\n",
    "            glob.glob(os.path.join(patient_path, t, \"*\")), \n",
    "            key=lambda x: int(x[:-4].split(\"-\")[-1]),\n",
    "        )\n",
    "        data = load_dicom(t_paths[int(len(t_paths) * slice_i)])\n",
    "        plt.subplot(1, 4, i)\n",
    "        plt.imshow(data, cmap=\"gray\")\n",
    "        plt.title(f\"{t}\", fontsize=16)\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "    plt.suptitle(f\"MGMT_value: {mgmt_value}\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "for i in random.sample(range(train_df.shape[0]), 10):\n",
    "    _brats21id = train_df.iloc[i][\"BraTS21ID\"]\n",
    "    _mgmt_value = train_df.iloc[i][\"MGMT_value\"]\n",
    "    visualize_sample(brats21id=_brats21id, mgmt_value=_mgmt_value, slice_i=0.5)\n",
    "\n",
    "from matplotlib import animation, rc\n",
    "rc('animation', html='jshtml')\n",
    "\n",
    "\n",
    "def create_animation(ims):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    plt.axis('off')\n",
    "    im = plt.imshow(ims[0], cmap=\"gray\")\n",
    "\n",
    "    def animate_func(i):\n",
    "        im.set_array(ims[i])\n",
    "        return [im]\n",
    "\n",
    "    return animation.FuncAnimation(fig, animate_func, frames = len(ims), interval = 1000//24)\n",
    "\n",
    "def load_dicom_line(path):\n",
    "    t_paths = sorted(\n",
    "        glob.glob(os.path.join(path, \"*\")), \n",
    "        key=lambda x: int(x[:-4].split(\"-\")[-1]),\n",
    "    )\n",
    "    images = []\n",
    "    for filename in t_paths:\n",
    "        data = load_dicom(filename)\n",
    "        if data.max() == 0:\n",
    "            continue\n",
    "        images.append(data)\n",
    "        \n",
    "    return images\n",
    "\n",
    "images = load_dicom_line(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/00000/FLAIR\")\n",
    "create_animation(images)\n",
    "\n",
    "Once Loop Reflect\n",
    "\n",
    "images = load_dicom_line(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/00000/T1w\")\n",
    "create_animation(images)\n",
    "\n",
    "Once Loop Reflect\n",
    "\n",
    "images = load_dicom_line(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/00000/T1wCE\")\n",
    "create_animation(images)\n",
    "\n",
    "images = load_dicom_line(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/00000/T2w\")\n",
    "create_animation(images)\n",
    "\n",
    "\n",
    "for y_true, y_pred in zip(list_y_true, list_y_pred):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([-0.01, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "Sample Submission\n",
    "\n",
    "submission = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv\")\n",
    "# submission.to_csv(\"submission.csv\", index=False)\n",
    "submission\n",
    "\n",
    "package_path = \"../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master/\"\n",
    "import sys \n",
    "sys.path.append(package_path)\n",
    "\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils import data as torch_data\n",
    "from sklearn import model_selection as sk_model_selection\n",
    "from torch.nn import functional as torch_functional\n",
    "import efficientnet_pytorch\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "df = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train_labels.csv\")\n",
    "df_train, df_valid = sk_model_selection.train_test_split(\n",
    "    df, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=train_df[\"MGMT_value\"],\n",
    ")\n",
    "\n",
    "class DataRetriever(torch_data.Dataset):\n",
    "    def __init__(self, paths, targets):\n",
    "        self.paths = paths\n",
    "        self.targets = targets\n",
    "          \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        _id = self.paths[index]\n",
    "        patient_path = f\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/{str(_id).zfill(5)}/\"\n",
    "        channels = []\n",
    "        for t in (\"FLAIR\", \"T1w\", \"T1wCE\"): # \"T2w\"\n",
    "            t_paths = sorted(\n",
    "                glob.glob(os.path.join(patient_path, t, \"*\")), \n",
    "                key=lambda x: int(x[:-4].split(\"-\")[-1]),\n",
    "            )\n",
    "            # start, end = int(len(t_paths) * 0.475), int(len(t_paths) * 0.525)\n",
    "            x = len(t_paths)\n",
    "            if x < 10:\n",
    "                r = range(x)\n",
    "            else:\n",
    "                d = x // 10\n",
    "                r = range(d, x - d, d)\n",
    "                \n",
    "            channel = []\n",
    "            # for i in range(start, end + 1):\n",
    "            for i in r:\n",
    "                channel.append(cv2.resize(load_dicom(t_paths[i]), (256, 256)) / 255)\n",
    "            channel = np.mean(channel, axis=0)\n",
    "            channels.append(channel)\n",
    "            \n",
    "        y = torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        \n",
    "        return {\"X\": torch.tensor(channels).float(), \"y\": y}\n",
    "\n",
    "train_data_retriever = DataRetriever(\n",
    "    df_train[\"BraTS21ID\"].values, \n",
    "    df_train[\"MGMT_value\"].values, \n",
    ")\n",
    "\n",
    "valid_data_retriever = DataRetriever(\n",
    "    df_valid[\"BraTS21ID\"].values, \n",
    "    df_valid[\"MGMT_value\"].values,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    plt.imshow(train_data_retriever[100][\"X\"].numpy()[i], cmap=\"gray\")\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = efficientnet_pytorch.EfficientNet.from_name(\"efficientnet-b0\")\n",
    "        checkpoint = torch.load(\"../input/efficientnet-pytorch/efficientnet-b0-08094119.pth\")\n",
    "        self.net.load_state_dict(checkpoint)\n",
    "        n_features = self.net._fc.in_features\n",
    "        self.net._fc = nn.Linear(in_features=n_features, out_features=1, bias=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out\n",
    "\n",
    "class LossMeter:\n",
    "    def __init__(self):\n",
    "        self.avg = 0\n",
    "        self.n = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        self.n += 1\n",
    "        # incremental update\n",
    "        self.avg = val / self.n + (self.n - 1) / self.n * self.avg\n",
    "\n",
    "        \n",
    "class AccMeter:\n",
    "    def __init__(self):\n",
    "        self.avg = 0\n",
    "        self.n = 0\n",
    "        \n",
    "    def update(self, y_true, y_pred):\n",
    "        y_true = y_true.cpu().numpy().astype(int)\n",
    "        y_pred = y_pred.cpu().numpy() >= 0\n",
    "        last_n = self.n\n",
    "        self.n += len(y_true)\n",
    "        true_count = np.sum(y_true == y_pred)\n",
    "        # incremental update\n",
    "        self.avg = true_count / self.n + last_n / self.n * self.avg\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        model, \n",
    "        device, \n",
    "        optimizer, \n",
    "        criterion, \n",
    "        loss_meter, \n",
    "        score_meter\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.loss_meter = loss_meter\n",
    "        self.score_meter = score_meter\n",
    "        \n",
    "        self.best_valid_score = -np.inf\n",
    "        self.n_patience = 0\n",
    "        \n",
    "        self.messages = {\n",
    "            \"epoch\": \"[Epoch {}: {}] loss: {:.5f}, score: {:.5f}, time: {} s\",\n",
    "            \"checkpoint\": \"The score improved from {:.5f} to {:.5f}. Save model to '{}'\",\n",
    "            \"patience\": \"\\nValid score didn't improve last {} epochs.\"\n",
    "        }\n",
    "    \n",
    "    def fit(self, epochs, train_loader, valid_loader, save_path, patience):        \n",
    "        for n_epoch in range(1, epochs + 1):\n",
    "            self.info_message(\"EPOCH: {}\", n_epoch)\n",
    "            \n",
    "            train_loss, train_score, train_time = self.train_epoch(train_loader)\n",
    "            valid_loss, valid_score, valid_time = self.valid_epoch(valid_loader)\n",
    "            \n",
    "            self.info_message(\n",
    "                self.messages[\"epoch\"], \"Train\", n_epoch, train_loss, train_score, train_time\n",
    "            )\n",
    "            \n",
    "            self.info_message(\n",
    "                self.messages[\"epoch\"], \"Valid\", n_epoch, valid_loss, valid_score, valid_time\n",
    "            )\n",
    "\n",
    "            if True:\n",
    "#             if self.best_valid_score < valid_score:\n",
    "                self.info_message(\n",
    "                    self.messages[\"checkpoint\"], self.best_valid_score, valid_score, save_path\n",
    "                )\n",
    "                self.best_valid_score = valid_score\n",
    "                self.save_model(n_epoch, save_path)\n",
    "                self.n_patience = 0\n",
    "            else:\n",
    "                self.n_patience += 1\n",
    "            \n",
    "            if self.n_patience >= patience:\n",
    "                self.info_message(self.messages[\"patience\"], patience)\n",
    "                break\n",
    "            \n",
    "    def train_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        t = time.time()\n",
    "        train_loss = self.loss_meter()\n",
    "        train_score = self.score_meter()\n",
    "        \n",
    "        for step, batch in enumerate(train_loader, 1):\n",
    "            X = batch[\"X\"].to(self.device)\n",
    "            targets = batch[\"y\"].to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(X).squeeze(1)\n",
    "            \n",
    "            loss = self.criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            train_loss.update(loss.detach().item())\n",
    "            train_score.update(targets, outputs.detach())\n",
    "\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            _loss, _score = train_loss.avg, train_score.avg\n",
    "            message = 'Train Step {}/{}, train_loss: {:.5f}, train_score: {:.5f}'\n",
    "            self.info_message(message, step, len(train_loader), _loss, _score, end=\"\\r\")\n",
    "        \n",
    "        return train_loss.avg, train_score.avg, int(time.time() - t)\n",
    "    \n",
    "    def valid_epoch(self, valid_loader):\n",
    "        self.model.eval()\n",
    "        t = time.time()\n",
    "        valid_loss = self.loss_meter()\n",
    "        valid_score = self.score_meter()\n",
    "\n",
    "        for step, batch in enumerate(valid_loader, 1):\n",
    "            with torch.no_grad():\n",
    "                X = batch[\"X\"].to(self.device)\n",
    "                targets = batch[\"y\"].to(self.device)\n",
    "\n",
    "                outputs = self.model(X).squeeze(1)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "\n",
    "                valid_loss.update(loss.detach().item())\n",
    "                valid_score.update(targets, outputs)\n",
    "                \n",
    "            _loss, _score = valid_loss.avg, valid_score.avg\n",
    "            message = 'Valid Step {}/{}, valid_loss: {:.5f}, valid_score: {:.5f}'\n",
    "            self.info_message(message, step, len(valid_loader), _loss, _score, end=\"\\r\")\n",
    "        \n",
    "        return valid_loss.avg, valid_score.avg, int(time.time() - t)\n",
    "    \n",
    "    def save_model(self, n_epoch, save_path):\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": self.model.state_dict(),\n",
    "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                \"best_valid_score\": self.best_valid_score,\n",
    "                \"n_epoch\": n_epoch,\n",
    "            },\n",
    "            save_path,\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def info_message(message, *args, end=\"\\n\"):\n",
    "        print(message.format(*args), end=end)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_data_retriever = DataRetriever(\n",
    "    df_train[\"BraTS21ID\"].values, \n",
    "    df_train[\"MGMT_value\"].values, \n",
    ")\n",
    "\n",
    "valid_data_retriever = DataRetriever(\n",
    "    df_valid[\"BraTS21ID\"].values, \n",
    "    df_valid[\"MGMT_value\"].values,\n",
    ")\n",
    "\n",
    "train_loader = torch_data.DataLoader(\n",
    "    train_data_retriever,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "valid_loader = torch_data.DataLoader(\n",
    "    valid_data_retriever, \n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "model = Model()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch_functional.binary_cross_entropy_with_logits\n",
    "\n",
    "trainer = Trainer(\n",
    "    model, \n",
    "    device, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    LossMeter, \n",
    "    AccMeter\n",
    ")\n",
    "\n",
    "history = trainer.fit(\n",
    "    10, \n",
    "    train_loader, \n",
    "    valid_loader, \n",
    "    f\"best-model-0.pth\", \n",
    "    100,\n",
    ")\n",
    "\n",
    "models = []\n",
    "for i in range(1):\n",
    "    model = Model()\n",
    "    model.to(device)\n",
    "    \n",
    "    checkpoint = torch.load(f\"best-model-{i}.pth\")\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    model.eval()\n",
    "    \n",
    "    models.append(model)\n",
    "\n",
    "class DataRetriever(torch_data.Dataset):\n",
    "    def __init__(self, paths):\n",
    "        self.paths = paths\n",
    "          \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        _id = self.paths[index]\n",
    "        patient_path = f\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/{str(_id).zfill(5)}/\"\n",
    "        channels = []\n",
    "        for t in (\"FLAIR\", \"T1w\", \"T1wCE\"): # \"T2w\"\n",
    "            t_paths = sorted(\n",
    "                glob.glob(os.path.join(patient_path, t, \"*\")), \n",
    "                key=lambda x: int(x[:-4].split(\"-\")[-1]),\n",
    "            )\n",
    "            # start, end = int(len(t_paths) * 0.475), int(len(t_paths) * 0.525)\n",
    "            x = len(t_paths)\n",
    "            if x < 10:\n",
    "                r = range(x)\n",
    "            else:\n",
    "                d = x // 10\n",
    "                r = range(d, x - d, d)\n",
    "                \n",
    "            channel = []\n",
    "            # for i in range(start, end + 1):\n",
    "            for i in r:\n",
    "                channel.append(cv2.resize(load_dicom(t_paths[i]), (256, 256)) / 255)\n",
    "            channel = np.mean(channel, axis=0)\n",
    "            channels.append(channel)\n",
    "        \n",
    "        return {\"X\": torch.tensor(channels).float(), \"id\": _id}\n",
    "\n",
    "submission = pd.read_csv(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/sample_submission.csv\")\n",
    "\n",
    "test_data_retriever = DataRetriever(\n",
    "    submission[\"BraTS21ID\"].values, \n",
    ")\n",
    "\n",
    "test_loader = torch_data.DataLoader(\n",
    "    test_data_retriever,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "y_pred = []\n",
    "ids = []\n",
    "\n",
    "for e, batch in enumerate(test_loader):\n",
    "    print(f\"{e}/{len(test_loader)}\", end=\"\\r\")\n",
    "    with torch.no_grad():\n",
    "        tmp_pred = np.zeros((batch[\"X\"].shape[0], ))\n",
    "        for model in models:\n",
    "            tmp_res = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n",
    "            tmp_pred += tmp_res\n",
    "        y_pred.extend(tmp_pred)\n",
    "        ids.extend(batch[\"id\"].numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8663501",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in random.sample(range(train_df.shape[0]), 10):\n",
    "    _brats21id = train_df.iloc[i][\"BraTS21ID\"]\n",
    "    _mgmt_value = train_df.iloc[i][\"MGMT_value\"]\n",
    "    visualize_sample(brats21id=_brats21id, mgmt_value=_mgmt_value, slice_i=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277d5834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation, rc\n",
    "rc('animation', html='jshtml')\n",
    "\n",
    "def create_animation(ims):\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    plt.axis('off')\n",
    "    im = plt.imshow(ims[0], cmap=\"gray\")\n",
    "\n",
    "    def animate_func(i):\n",
    "        im.set_array(ims[i])\n",
    "        return [im]\n",
    "\n",
    "    return animation.FuncAnimation(fig, animate_func, frames = len(ims), interval = 1000//24)\n",
    "\n",
    "def load_dicom_line(path):\n",
    "    t_paths = sorted(\n",
    "        glob.glob(os.path.join(path, \"*\")), \n",
    "        key=lambda x: int(x[:-4].split(\"-\")[-1]),\n",
    "    )\n",
    "    images = []\n",
    "    for filename in t_paths:\n",
    "        data = load_dicom(filename)\n",
    "        if data.max() == 0:\n",
    "            continue\n",
    "        images.append(data)\n",
    "        \n",
    "    return images\n",
    "\n",
    "images = load_dicom_line(\"../train/00000/FLAIR\")\n",
    "create_animation(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70772c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = efficientnet_pytorch.EfficientNet.from_name(\"efficientnet-b0\")\n",
    "        checkpoint = torch.load(\"../input/efficientnet-pytorch/efficientnet-b0-08094119.pth\")\n",
    "        self.net.load_state_dict(checkpoint)\n",
    "        n_features = self.net._fc.in_features\n",
    "        self.net._fc = nn.Linear(in_features=n_features, out_features=1, bias=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        return out\n",
    "\n",
    "class LossMeter:\n",
    "    def __init__(self):\n",
    "        self.avg = 0\n",
    "        self.n = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        self.n += 1\n",
    "        # incremental update\n",
    "        self.avg = val / self.n + (self.n - 1) / self.n * self.avg\n",
    "\n",
    "        \n",
    "class AccMeter:\n",
    "    def __init__(self):\n",
    "        self.avg = 0\n",
    "        self.n = 0\n",
    "        \n",
    "    def update(self, y_true, y_pred):\n",
    "        y_true = y_true.cpu().numpy().astype(int)\n",
    "        y_pred = y_pred.cpu().numpy() >= 0\n",
    "        last_n = self.n\n",
    "        self.n += len(y_true)\n",
    "        true_count = np.sum(y_true == y_pred)\n",
    "        # incremental update\n",
    "        self.avg = true_count / self.n + last_n / self.n * self.avg\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, \n",
    "        model, \n",
    "        device, \n",
    "        optimizer, \n",
    "        criterion, \n",
    "        loss_meter, \n",
    "        score_meter\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.loss_meter = loss_meter\n",
    "        self.score_meter = score_meter\n",
    "        \n",
    "        self.best_valid_score = -np.inf\n",
    "        self.n_patience = 0\n",
    "        \n",
    "        self.messages = {\n",
    "            \"epoch\": \"[Epoch {}: {}] loss: {:.5f}, score: {:.5f}, time: {} s\",\n",
    "            \"checkpoint\": \"The score improved from {:.5f} to {:.5f}. Save model to '{}'\",\n",
    "            \"patience\": \"\\nValid score didn't improve last {} epochs.\"\n",
    "        }\n",
    "    \n",
    "    def fit(self, epochs, train_loader, valid_loader, save_path, patience):        \n",
    "        for n_epoch in range(1, epochs + 1):\n",
    "            self.info_message(\"EPOCH: {}\", n_epoch)\n",
    "            \n",
    "            train_loss, train_score, train_time = self.train_epoch(train_loader)\n",
    "            valid_loss, valid_score, valid_time = self.valid_epoch(valid_loader)\n",
    "            \n",
    "            self.info_message(\n",
    "                self.messages[\"epoch\"], \"Train\", n_epoch, train_loss, train_score, train_time\n",
    "            )\n",
    "            \n",
    "            self.info_message(\n",
    "                self.messages[\"epoch\"], \"Valid\", n_epoch, valid_loss, valid_score, valid_time\n",
    "            )\n",
    "\n",
    "            if True:\n",
    "#             if self.best_valid_score < valid_score:\n",
    "                self.info_message(\n",
    "                    self.messages[\"checkpoint\"], self.best_valid_score, valid_score, save_path\n",
    "                )\n",
    "                self.best_valid_score = valid_score\n",
    "                self.save_model(n_epoch, save_path)\n",
    "                self.n_patience = 0\n",
    "            else:\n",
    "                self.n_patience += 1\n",
    "            \n",
    "            if self.n_patience >= patience:\n",
    "                self.info_message(self.messages[\"patience\"], patience)\n",
    "                break\n",
    "            \n",
    "    def train_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        t = time.time()\n",
    "        train_loss = self.loss_meter()\n",
    "        train_score = self.score_meter()\n",
    "        \n",
    "        for step, batch in enumerate(train_loader, 1):\n",
    "            X = batch[\"X\"].to(self.device)\n",
    "            targets = batch[\"y\"].to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(X).squeeze(1)\n",
    "            \n",
    "            loss = self.criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            train_loss.update(loss.detach().item())\n",
    "            train_score.update(targets, outputs.detach())\n",
    "\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            _loss, _score = train_loss.avg, train_score.avg\n",
    "            message = 'Train Step {}/{}, train_loss: {:.5f}, train_score: {:.5f}'\n",
    "            self.info_message(message, step, len(train_loader), _loss, _score, end=\"\\r\")\n",
    "        \n",
    "        return train_loss.avg, train_score.avg, int(time.time() - t)\n",
    "    \n",
    "    def valid_epoch(self, valid_loader):\n",
    "        self.model.eval()\n",
    "        t = time.time()\n",
    "        valid_loss = self.loss_meter()\n",
    "        valid_score = self.score_meter()\n",
    "\n",
    "        for step, batch in enumerate(valid_loader, 1):\n",
    "            with torch.no_grad():\n",
    "                X = batch[\"X\"].to(self.device)\n",
    "                targets = batch[\"y\"].to(self.device)\n",
    "\n",
    "                outputs = self.model(X).squeeze(1)\n",
    "                loss = self.criterion(outputs, targets)\n",
    "\n",
    "                valid_loss.update(loss.detach().item())\n",
    "                valid_score.update(targets, outputs)\n",
    "                \n",
    "            _loss, _score = valid_loss.avg, valid_score.avg\n",
    "            message = 'Valid Step {}/{}, valid_loss: {:.5f}, valid_score: {:.5f}'\n",
    "            self.info_message(message, step, len(valid_loader), _loss, _score, end=\"\\r\")\n",
    "        \n",
    "        return valid_loss.avg, valid_score.avg, int(time.time() - t)\n",
    "    \n",
    "    def save_model(self, n_epoch, save_path):\n",
    "        torch.save(\n",
    "            {\n",
    "                \"model_state_dict\": self.model.state_dict(),\n",
    "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                \"best_valid_score\": self.best_valid_score,\n",
    "                \"n_epoch\": n_epoch,\n",
    "            },\n",
    "            save_path,\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def info_message(message, *args, end=\"\\n\"):\n",
    "        print(message.format(*args), end=end)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_data_retriever = DataRetriever(\n",
    "    df_train[\"BraTS21ID\"].values, \n",
    "    df_train[\"MGMT_value\"].values, \n",
    ")\n",
    "\n",
    "valid_data_retriever = DataRetriever(\n",
    "    df_valid[\"BraTS21ID\"].values, \n",
    "    df_valid[\"MGMT_value\"].values,\n",
    ")\n",
    "\n",
    "train_loader = torch_data.DataLoader(\n",
    "    train_data_retriever,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "valid_loader = torch_data.DataLoader(\n",
    "    valid_data_retriever, \n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "model = Model()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch_functional.binary_cross_entropy_with_logits\n",
    "\n",
    "trainer = Trainer(\n",
    "    model, \n",
    "    device, \n",
    "    optimizer, \n",
    "    criterion, \n",
    "    LossMeter, \n",
    "    AccMeter\n",
    ")\n",
    "\n",
    "history = trainer.fit(\n",
    "    10, \n",
    "    train_loader, \n",
    "    valid_loader, \n",
    "    f\"best-model-0.pth\", \n",
    "    100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed28f10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdd79ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa9e579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
